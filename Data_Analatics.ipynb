{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39007fe6",
   "metadata": {},
   "source": [
    "Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18276477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyyaml in c:\\users\\judej\\appdata\\roaming\\python\\python313\\site-packages (6.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d90fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.0-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\judej\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\judej\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\judej\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\judej\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\judej\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.0-cp313-cp313-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.1/11.0 MB 13.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 16.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 19.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 17.5 MB/s eta 0:00:00\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "775edb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "month_folders = [\n",
    "    r\"C:\\Users\\judej\\OneDrive\\Desktop\\Stock analaysis\\Data\\2023-10\",\n",
    "    r\"C:\\Users\\judej\\OneDrive\\Desktop\\Stock analaysis\\Data\\2023-11\",\n",
    "    r\"C:\\Users\\judej\\OneDrive\\Desktop\\Stock analaysis\\Data\\2023-12\",\n",
    "    r\"C:\\Users\\judej\\OneDrive\\Desktop\\Stock analaysis\\Data\\2024-01\",\n",
    "    r\"C:\\Users\\judej\\OneDrive\\Desktop\\Stock analaysis\\Data\\2024-02\",\n",
    "    r\"C:\\Users\\judej\\OneDrive\\Desktop\\Stock analaysis\\Data\\2024-03\",\n",
    "    r\"C:\\Users\\judej\\OneDrive\\Desktop\\Stock analaysis\\Data\\2024-04\",\n",
    "    r\"C:\\Users\\judej\\OneDrive\\Desktop\\Stock analaysis\\Data\\2024-05\",\n",
    "    r\"C:\\Users\\judej\\OneDrive\\Desktop\\Stock analaysis\\Data\\2024-06\",\n",
    "    r\"C:\\Users\\judej\\OneDrive\\Desktop\\Stock analaysis\\Data\\2024-07\",\n",
    "    r\"C:\\Users\\judej\\OneDrive\\Desktop\\Stock analaysis\\Data\\2024-08\",\n",
    "    r\"C:\\Users\\judej\\OneDrive\\Desktop\\Stock analaysis\\Data\\2024-09\",\n",
    "    r\"C:\\Users\\judej\\OneDrive\\Desktop\\Stock analaysis\\Data\\2024-10\",\n",
    "    r\"C:\\Users\\judej\\OneDrive\\Desktop\\Stock analaysis\\Data\\2024-11\"\n",
    "]\n",
    "\n",
    "\n",
    "sector_csv = r\"C:\\Users\\judej\\OneDrive\\Desktop\\Stock analaysis\\Data\\Sector_data - Sheet1.csv\"\n",
    "\n",
    "\n",
    "individual_csv_dir = r\"C:\\Users\\judej\\OneDrive\\Desktop\\Stock analaysis\\Main\"\n",
    "final_csv_path = os.path.join(individual_csv_dir, \"all_data_with_sector.csv\")\n",
    "os.makedirs(individual_csv_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "sector_df = pd.read_csv(sector_csv)\n",
    "sector_df.columns = sector_df.columns.str.strip()\n",
    "\n",
    "sector_df['Ticker'] = sector_df['Symbol'].str.split(\":\").str[-1].str.strip()\n",
    "sector_df['Company'] = sector_df['COMPANY'].str.strip()\n",
    "sector_df['Sector'] = sector_df['sector'].str.strip()\n",
    "\n",
    "sector_map = dict(zip(sector_df['Ticker'], sector_df['Sector']))\n",
    "company_map = dict(zip(sector_df['Ticker'], sector_df['Company']))\n",
    "\n",
    "\n",
    "ticker_corrections = {\n",
    "    'ADANIENT': 'ADANIGREEN',\n",
    "    'BHARTIARTL': 'AIRTEL',\n",
    "    'TATACONSUM': 'TATACONSUMER',\n",
    "    'BRITANNIA': 'NESTLEIND'\n",
    "}\n",
    "\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for month_path in month_folders:\n",
    "    for file in os.listdir(month_path):\n",
    "        if file.endswith(\".yaml\"):\n",
    "            file_path = os.path.join(month_path, file)\n",
    "            with open(file_path, \"r\") as f:\n",
    "                day_data = yaml.safe_load(f)\n",
    "                for entry in day_data:\n",
    "                    raw_ticker = entry['Ticker']\n",
    "                    corrected_ticker = ticker_corrections.get(raw_ticker, raw_ticker)\n",
    "                    entry['Ticker'] = corrected_ticker\n",
    "                    entry['Sector'] = sector_map.get(corrected_ticker, \"Unknown\")\n",
    "                    entry['Company'] = company_map.get(corrected_ticker, \"Unknown\")\n",
    "                    all_data.append(entry)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "for ticker, group_df in df.groupby(\"Ticker\"):\n",
    "    output_path = os.path.join(individual_csv_dir, f\"{ticker}.csv\")\n",
    "    group_df.to_csv(output_path, index=False)\n",
    "\n",
    "df.to_csv(final_csv_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322a32a2",
   "metadata": {},
   "source": [
    "Data Frame creation For Requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d245996f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volatility_Analysis null \n",
      " Ticker        0\n",
      "Company       0\n",
      "Volatility    0\n",
      "dtype: int64 \n",
      "\n",
      "Cumulative_Return null \n",
      " date                 0\n",
      "Ticker               0\n",
      "Company              0\n",
      "Cumulative_Return    0\n",
      "dtype: int64 \n",
      "\n",
      "Sector_wise_Performance null \n",
      " Sector           0\n",
      "Yearly_Return    0\n",
      "dtype: int64 \n",
      "\n",
      "Correlation null \n",
      " Company\n",
      "ADANI ENTERPRISES      0\n",
      "ADANI PORTS & SEZ      0\n",
      "APOLLO HOSPITALS       0\n",
      "ASIAN PAINTS           0\n",
      "AXIS BANK              0\n",
      "BAJAJ AUTO             0\n",
      "BAJAJ FINANCE          0\n",
      "BAJAJ FINSERV          0\n",
      "BHARAT ELECTRONICS     0\n",
      "BHARTI AIRTEL          0\n",
      "BPCL                   0\n",
      "CIPLA                  0\n",
      "COAL INDIA             0\n",
      "DR. REDDYS LAB         0\n",
      "EICHER MOTORS          0\n",
      "GRASIM                 0\n",
      "HCL TECHNOLOGIES       0\n",
      "HDFC BANK              0\n",
      "HDFC LIFE INSURANCE    0\n",
      "HERO MOTOCORP          0\n",
      "HINDALCO               0\n",
      "HINDUSTAN UNILEVER     0\n",
      "ICICI BANK             0\n",
      "INDUSIND BANK          0\n",
      "INFOSYS                0\n",
      "ITC                    0\n",
      "JSW STEEL              0\n",
      "KOTAK MAHINDRA BANK    0\n",
      "L&T                    0\n",
      "M&M                    0\n",
      "MARUTI SUZUKI          0\n",
      "NESTLE                 0\n",
      "NTPC                   0\n",
      "ONGC                   0\n",
      "POWER GRID             0\n",
      "RELIANCE IND.          0\n",
      "SBI                    0\n",
      "SBI LIFE INSURANCE     0\n",
      "SHRIRAM FINANCE        0\n",
      "SUN PHARMA             0\n",
      "TATA CONSUMER          0\n",
      "TATA MOTORS            0\n",
      "TATA STEEL             0\n",
      "TCS                    0\n",
      "TECH MAHINDRA          0\n",
      "TITAN                  0\n",
      "TRENT                  0\n",
      "ULTRATECH CEMENT       0\n",
      "WIPRO                  0\n",
      "dtype: int64 \n",
      "\n",
      "Month_wise_data null \n",
      " month           0\n",
      "Ticker          0\n",
      "Company         0\n",
      "Daily_Return    0\n",
      "Rank            0\n",
      "dtype: int64 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\judej\\AppData\\Local\\Temp\\ipykernel_12140\\3495646223.py:55: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(top_bottom_ranked)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "file_path = r\"C:\\Users\\judej\\OneDrive\\Desktop\\Stock analaysis\\Main\\all_data_with_sector.csv\"\n",
    "output_dir = r\"C:\\Users\\judej\\OneDrive\\Desktop\\Stock analaysis\\Main\\Required Df\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['month'] = df['date'].dt.to_period('M').astype(str)\n",
    "df.sort_values(by=['Ticker', 'date'], inplace=True)\n",
    "df['Prev_Close'] = df.groupby('Ticker')['close'].shift(1)\n",
    "df['Daily_Return'] = (df['close'] - df['Prev_Close']) / df['Prev_Close']\n",
    "df['Daily_Return'] = df['Daily_Return'].fillna(0)\n",
    "\n",
    "\n",
    "volatility_df = df.groupby(['Ticker', 'Company'])['Daily_Return'].std().reset_index()\n",
    "volatility_df.columns = ['Ticker', 'Company', 'Volatility']\n",
    "volatility_df.to_csv(os.path.join(output_dir, \"Volatility_Analysis.csv\"), index=False)\n",
    "\n",
    "\n",
    "df['Cumulative_Return'] = df.groupby('Ticker')['Daily_Return'].cumsum()\n",
    "cumulative_df = df[['date', 'Ticker', 'Company', 'Cumulative_Return']]\n",
    "cumulative_df.to_csv(os.path.join(output_dir, \"Cumulative_Return.csv\"), index=False)\n",
    "\n",
    "\n",
    "yearly_return_df = df.groupby('Ticker').agg(\n",
    "    Start_Close=('close', 'first'),\n",
    "    End_Close=('close', 'last'),\n",
    "    Sector=('Sector', 'last'),\n",
    "    Company=('Company', 'last')\n",
    ").reset_index()\n",
    "yearly_return_df['Yearly_Return'] = (\n",
    "    (yearly_return_df['End_Close'] - yearly_return_df['Start_Close']) / yearly_return_df['Start_Close']\n",
    ")\n",
    "sector_perf_df = yearly_return_df.groupby('Sector')['Yearly_Return'].mean().reset_index()\n",
    "sector_perf_df.to_csv(os.path.join(output_dir, \"Sector_wise_Performance.csv\"), index=False)\n",
    "\n",
    "pivot_company_df = df.groupby(['date', 'Company'])['Daily_Return'].mean().unstack()\n",
    "correlation_company_df = pivot_company_df.corr()\n",
    "correlation_company_df.to_csv(os.path.join(output_dir, \"Correlation.csv\"))\n",
    "\n",
    "\n",
    "monthly_return_df = df.groupby(['month', 'Ticker', 'Company'])['Daily_Return'].sum().reset_index()\n",
    "\n",
    "def top_bottom_ranked(group):\n",
    "    top = group.nlargest(5, 'Daily_Return').copy()\n",
    "    top['Rank'] = range(1, 6)\n",
    "    bottom = group.nsmallest(5, 'Daily_Return').copy()\n",
    "    bottom['Rank'] = range(-5, 0)\n",
    "    return pd.concat([top, bottom])\n",
    "\n",
    "monthly_top_bottom_ranked_df = (\n",
    "    monthly_return_df.groupby('month', group_keys=False)\n",
    "    .apply(top_bottom_ranked)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "monthly_top_bottom_ranked_df['month'] = pd.to_datetime(monthly_top_bottom_ranked_df['month']).dt.strftime('%B %Y')\n",
    "monthly_top_bottom_ranked_df.to_csv(os.path.join(output_dir, \"Month_wise_data.csv\"), index=False)\n",
    "\n",
    "\n",
    "print(\"Volatility_Analysis null \\n\", volatility_df.isnull().sum(), \"\\n\")\n",
    "print(\"Cumulative_Return null \\n\", cumulative_df.isnull().sum(), \"\\n\")\n",
    "print(\"Sector_wise_Performance null \\n\", sector_perf_df.isnull().sum(), \"\\n\")\n",
    "print(\"Correlation null \\n\", correlation_company_df.isnull().sum(), \"\\n\")\n",
    "print(\"Month_wise_data null \\n\", monthly_top_bottom_ranked_df.isnull().sum(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6363a1",
   "metadata": {},
   "source": [
    "Data Sql Insertion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a81afe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting mysql-connector-python\n",
      "  Downloading mysql_connector_python-9.3.0-cp313-cp313-win_amd64.whl.metadata (7.7 kB)\n",
      "Downloading mysql_connector_python-9.3.0-cp313-cp313-win_amd64.whl (16.4 MB)\n",
      "   ---------------------------------------- 0.0/16.4 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 5.2/16.4 MB 33.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.8/16.4 MB 31.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 16.4/16.4 MB 31.0 MB/s eta 0:00:00\n",
      "Installing collected packages: mysql-connector-python\n",
      "Successfully installed mysql-connector-python-9.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mysql-connector-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08fb0ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector as mysql\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "connection = mysql.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='root',\n",
    "    database='stock_analysis_db',\n",
    "    port=3306\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS all_data_with_sector (\n",
    "    Ticker VARCHAR(20),\n",
    "    close FLOAT,\n",
    "    date DATETIME,\n",
    "    high FLOAT,\n",
    "    low FLOAT,\n",
    "    month VARCHAR(20),\n",
    "    open FLOAT,\n",
    "    volume BIGINT,\n",
    "    Sector VARCHAR(100),\n",
    "    Company VARCHAR(100)\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Volatility_Analysis (\n",
    "    Ticker VARCHAR(20),\n",
    "    Company VARCHAR(100),\n",
    "    Volatility FLOAT\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Cumulative_Return (\n",
    "    date DATETIME,\n",
    "    Ticker VARCHAR(20),\n",
    "    Company VARCHAR(100),\n",
    "    Cumulative_Return FLOAT\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Sector_wise_Performance (\n",
    "    Sector VARCHAR(100),\n",
    "    Yearly_Return FLOAT\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Month_wise_data (\n",
    "    month VARCHAR(20),\n",
    "    Ticker VARCHAR(20),\n",
    "    Company VARCHAR(100),\n",
    "    Daily_Return FLOAT,\n",
    "    `Rank` INT\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "main_csv = r\"C:\\Users\\judej\\OneDrive\\Desktop\\Stock analaysis\\Main\\all_data_with_sector.csv\"\n",
    "output_dir = r\"C:\\Users\\judej\\OneDrive\\Desktop\\Stock analaysis\\Main\\Required Df\"\n",
    "\n",
    "df_sector = pd.read_csv(main_csv)\n",
    "df_volatility = pd.read_csv(os.path.join(output_dir, \"Volatility_Analysis.csv\"))\n",
    "df_cum_return = pd.read_csv(os.path.join(output_dir, \"Cumulative_Return.csv\"))\n",
    "df_sector_perf = pd.read_csv(os.path.join(output_dir, \"Sector_wise_Performance.csv\"))\n",
    "df_monthly = pd.read_csv(os.path.join(output_dir, \"Month_wise_data.csv\"))\n",
    "\n",
    "\n",
    "df_sector.columns = df_sector.columns.str.strip()\n",
    "df_volatility.columns = df_volatility.columns.str.strip()\n",
    "df_cum_return.columns = df_cum_return.columns.str.strip()\n",
    "df_sector_perf.columns = df_sector_perf.columns.str.strip()\n",
    "df_monthly.columns = df_monthly.columns.str.strip()\n",
    "\n",
    "\n",
    "\n",
    "insert_sector = \"\"\"\n",
    "INSERT INTO all_data_with_sector \n",
    "(Ticker, close, date, high, low, month, open, volume, Sector, Company)\n",
    "VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "\"\"\"\n",
    "for _, row in df_sector.iterrows():\n",
    "    cursor.execute(insert_sector, tuple(row))\n",
    "\n",
    "insert_vol = \"\"\"\n",
    "INSERT INTO Volatility_Analysis (Ticker, Company, Volatility)\n",
    "VALUES (%s, %s, %s);\n",
    "\"\"\"\n",
    "for _, row in df_volatility.iterrows():\n",
    "    cursor.execute(insert_vol, (row['Ticker'], row['Company'], row['Volatility']))\n",
    "\n",
    "insert_cum = \"\"\"\n",
    "INSERT INTO Cumulative_Return (date, Ticker, Company, Cumulative_Return)\n",
    "VALUES (%s, %s, %s, %s);\n",
    "\"\"\"\n",
    "for _, row in df_cum_return.iterrows():\n",
    "    cursor.execute(insert_cum, (row['date'], row['Ticker'], row['Company'], row['Cumulative_Return']))\n",
    "\n",
    "insert_sector_perf = \"\"\"\n",
    "INSERT INTO Sector_wise_Performance (Sector, Yearly_Return)\n",
    "VALUES (%s, %s);\n",
    "\"\"\"\n",
    "for _, row in df_sector_perf.iterrows():\n",
    "    cursor.execute(insert_sector_perf, (row['Sector'], row['Yearly_Return']))\n",
    "\n",
    "insert_monthly = \"\"\"\n",
    "INSERT INTO Month_wise_data (month, Ticker, Company, Daily_Return, `Rank`)\n",
    "VALUES (%s, %s, %s, %s, %s);\n",
    "\"\"\"\n",
    "for _, row in df_monthly.iterrows():\n",
    "    cursor.execute(insert_monthly, (\n",
    "        row['month'], row['Ticker'], row['Company'], row['Daily_Return'], row['Rank']\n",
    "    ))\n",
    "\n",
    "# === Finalize ===\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2c9df6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
